{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTWNdevjtUMG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CQbsgbLuAFn"
      },
      "outputs": [],
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh2io6Jyu3Ri"
      },
      "outputs": [],
      "source": [
        "!unzip -q train.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make folders for dataset**"
      ],
      "metadata": {
        "id": "LZ1brZhBsg6C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awNiDfKavRX0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "print( len( os.listdir('/content/train/') ) ) #count the number of img files\n",
        "\n",
        "#move files into either cat or dog folder\n",
        "\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "for i in os.listdir('/content/train/'): #i = file name like cat1.jpg\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile( '/content/train/' + i, '/content/dataset/cat/' + i )\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile( '/content/train/' + i, '/content/dataset/dog/' + i )\n",
        "\n",
        "\n",
        "# tf.keras.preprocessing.image.dataset_from_directory()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess the tensor data**"
      ],
      "metadata": {
        "id": "FHkoazE0q21W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdoMapk_wwAO"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=64, #64 images at once, update w \n",
        "    subset='training', #training has 80% of data\n",
        "    validation_split=0.2, #20% of data for validation dataset, use 80% of data for training\n",
        "    seed=1234,\n",
        ")\n",
        "\n",
        "#train_ds format = ( (xxxx = 64x64 image array), (yyyyy = 0 or 1 for dog/cat) )\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=64, \n",
        "    subset='validation', #validation has 20% of data\n",
        "    validation_split=0.2, \n",
        "    seed=1234,\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "def preprocess_func(image_data, key): #introduce preprocessor to increase flops and find optimized w quicker\n",
        "  image_data = tf.cast(image_data / 255.0, tf.float32 )\n",
        "  return image_data, key\n",
        "\n",
        "train_ds = train_ds.map(preprocess_func) #compress input data into range 0-1 rather than using 0-255\n",
        "val_ds = val_ds.map(preprocess_func)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# for i, answer in train_ds.take(1): \n",
        "#   print(i) \n",
        "#   print(answer)\n",
        "#   plt.imshow( i[0].numpy().astype('uint8') )\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a model**"
      ],
      "metadata": {
        "id": "kkuhOHD9q6rN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVIV1d_vGwhP"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    #Augment image before putting it into model\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(64,64,3) ),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D( filters=32, kernel_size=(3,3), padding=\"same\", activation='relu' ), #image size = 64x64, color = 3 for rgb\n",
        "    tf.keras.layers.MaxPooling2D( pool_size=(2,2) ),\n",
        "    \n",
        "    tf.keras.layers.Conv2D( filters=64, kernel_size=(3,3), padding=\"same\", activation='relu' ), #image size = 64x64, color = 3 for rgb\n",
        "    tf.keras.layers.MaxPooling2D( pool_size=(2,2) ),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.2), #to prevent overfitting, remove 20% of previous layer's nodes\n",
        "    \n",
        "    tf.keras.layers.Conv2D( filters=128, kernel_size=(3,3), padding=\"same\", activation='relu' ), #image size = 64x64, color = 3 for rgb\n",
        "    tf.keras.layers.MaxPooling2D( pool_size=(2,2) ),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    \n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    \n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") #sigmoid used to have one node for last layer = probability of dog or cat\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile( loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'] )\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Augmentation**"
      ],
      "metadata": {
        "id": "DEnRn9zfqbxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glxBEgdSH3OW"
      },
      "outputs": [],
      "source": [
        "#Augment image using image data generator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=20, #rotation\n",
        "    zoom_range=0.15, #zoom\n",
        "    width_shift_range=0.2, #shift\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,  #shear\n",
        "    horizontal_flip=True, #flip\n",
        "    fill_mode=\"nearest\", #how to fill in padding\n",
        ")\n",
        "\n",
        "train_dataset = train_generator.flow_from_directory( #behaves like image_dataset_from_directroy()\n",
        "    '/content/dataset',\n",
        "    class_mode='binary', #two = binary, more = categorical\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    target_size=(64,64),\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale=1./255) #no need to augment the validation dataset\n",
        "\n",
        "val_dataset = val_generator.flow_from_directory(\n",
        "    '/content/dataset',\n",
        "    class_mode='binary', #two = binary, more = categorical\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save a model or checkpoint after training**"
      ],
      "metadata": {
        "id": "xCMeYTdBqlXz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWOjgWtoL28J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "trainX = trainX.reshape( (trainX.shape[0], 28,28,1) )\n",
        "testX = testX.reshape( (testX.shape[0], 28,28,1) )\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten( input_shape=(28,28,1) ),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "call_back = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='checkpoint/mnist', #mnist{epoch} to store every epoch instead of overwriting and storing only last epoch\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "\n",
        "    # save checkpoint when val_acc is max\n",
        "\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "model.summary() #always require input_shape on first layer of the model\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=3, callbacks=[call_back]) #run callbacks in between each epoch to store the weights of the model = save checkpoint\n",
        "\n",
        "model.evaluate(testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WmzW2bJt2daA"
      },
      "outputs": [],
      "source": [
        "model.save('newFolder/model1') #to save the entire model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFlrHVhL2qbl"
      },
      "outputs": [],
      "source": [
        "loadedModel = tf.keras.models.load_model('newFolder/model1')\n",
        "loadedModel.summary()\n",
        "\n",
        "loadedModel.evaluate(testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAxaYJ6O5gkr"
      },
      "outputs": [],
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten( input_shape=(28,28,1) ),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model2.load_weights('checkpoint/mnist')\n",
        "\n",
        "model2.evaluate(testX, testY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tesorboard visulization, test automization usig EarlyStoppig**"
      ],
      "metadata": {
        "id": "L9v_mq2YqSom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh4R8wM3FcEH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "trainX = trainX.reshape( (trainX.shape[0], 28,28,1) )\n",
        "testX = testX.reshape( (testX.shape[0], 28,28,1) )\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "\n",
        "tensorboard = TensorBoard( log_dir='logs/{}'.format( 'first model' + str( int(time.time()) ) ))\n",
        "\n",
        "#EarlyStoppig\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping( monitor='val_accuracy', patience=3, mode='max' ) #after 3 epochs, stop training if there is no improvemt in val_acc, mode = 'min' for val_loss\n",
        "\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=300, callbacks=[tensorboard, es]) #run callbacks after each training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext TensorBoard"
      ],
      "metadata": {
        "id": "rtwZjeA6rxDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "h8h6_nSnsW4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a model with Functional API instead of Sequential**"
      ],
      "metadata": {
        "id": "Rp2q4hhjv5eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "trainX = trainX.reshape( (trainX.shape[0], 28,28,1) )\n",
        "testX = testX.reshape( (testX.shape[0], 28,28,1) )\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True) #preview a model"
      ],
      "metadata": {
        "id": "vjE7p67Tv4jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = tf.keras.layers.Input(shape=[28, 28])\n",
        "flatten1 = tf.keras.layers.Flatten()(input1) #input1 -> flatte1\n",
        "dense1 = tf.keras.layers.Dense(28*28, activaton='relu')(flatten1)\n",
        "reshape1= tf.keras.layers.Reshape( (28,28) )(dense1) #reshape size should be equal to previous layer's number of nodes\n",
        "\n",
        "concat1 = tf.keras.layers.Concatenate()([input1, reshape1]) \n",
        "flatten2 = tf.keras.layers.Flatten()(cocat1)\n",
        "output = tf.keras.layers.Dense(10, activation='softmax')(flatten2)\n",
        "\n",
        "model = tf.keras.Model(input1, output) #make a model with input and output\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True) #preview a model"
      ],
      "metadata": {
        "id": "rX8naz83whPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer learning**"
      ],
      "metadata": {
        "id": "hj6sG1Aq5SWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n",
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d .\n",
        "!unzip -q train.zip -d . "
      ],
      "metadata": {
        "id": "b4XxRRhz5R4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import tensorflow as tf \n",
        "import shutil\n",
        "\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile( '/content/train/' + i , '/content/dataset/cat/' + i )\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile( '/content/train/' + i , '/content/dataset/dog/' + i )\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(150,150),\n",
        "  batch_size=64,\n",
        "  subset='training',\n",
        "  validation_split=0.2,\n",
        "  seed=1234\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(150,150),\n",
        "  batch_size=64,\n",
        "  subset='validation',\n",
        "  validation_split=0.2,\n",
        "  seed=1234\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "def preprocess_func(image_data, key): #introduce preprocessor to increase flops and find optimized w quicker\n",
        "  image_data = tf.cast(image_data / 255.0, tf.float32 )\n",
        "  return image_data, key\n",
        "\n",
        "train_ds = train_ds.map(preprocess_func) #compress input data into range 0-1 rather than using 0-255\n",
        "val_ds = val_ds.map(preprocess_func)"
      ],
      "metadata": {
        "id": "6zn2quKK5ZL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download Inception_v3.h5, weight file"
      ],
      "metadata": {
        "id": "BqrwtFHX6IbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('inception_v3.h5', 'wb').write(r.content)"
      ],
      "metadata": {
        "id": "pEORuqHN5rhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. import Google's InceptionV3 model"
      ],
      "metadata": {
        "id": "dwU0weCj6TmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "inception_model = InceptionV3( input_shape=(150,150,3), include_top=False, weights=None ) \n",
        "#originally InceptioV3 takes input_shape=(299,299,3)\n",
        "#top layer = last output layer = last dense layer"
      ],
      "metadata": {
        "id": "WazEkAqj57-C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. integrate weight file and InceptionV3"
      ],
      "metadata": {
        "id": "Z9QLQvzH7A9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.load_weights('inception_v3.h5')\n",
        "\n",
        "inception_model.summary()"
      ],
      "metadata": {
        "id": "He7PGSfc7Hyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Set layers not trainable \n",
        "\n"
      ],
      "metadata": {
        "id": "S9FsWVh37oSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No fine tuning\n",
        "for i in inception_model.layers:\n",
        "  i.trainable = False\n",
        "\n",
        "#fine tuning = train inception model from mixed6 layer\n",
        "unfreeze = False\n",
        "for i in inception_model.layers:\n",
        "  if i.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "  if unfreeze == True:\n",
        "    i.trainable = True\n",
        "\n",
        "last_layer = inception_model.get_layer('mixed7')"
      ],
      "metadata": {
        "id": "1BA1qFsz7mBk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "layer1 = tf.keras.layers.Flatten()(last_layer.output)\n",
        "layer2 = tf.keras.layers.Dense(1024, activation='relu')(layer1)\n",
        "drop1 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer3 = tf.keras.layers.Dense(1, activation='sigmoid')(drop1) #1 for dog and cat classification\n",
        "\n",
        "model = tf.keras.Model(inception_model.input, layer3)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcIRPJmS8TUf",
        "outputId": "47b95738-fbc8-4147-c98c-0a3f194f9131"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "313/313 [==============================] - 1287s 4s/step - loss: 0.1610 - acc: 0.9524 - val_loss: 0.0872 - val_acc: 0.9622\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1220s 4s/step - loss: 0.0404 - acc: 0.9843 - val_loss: 0.0890 - val_acc: 0.9700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff9def8c700>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fine tuning = update weight by little = small learning rate in optimizer"
      ],
      "metadata": {
        "id": "7IIEwTMw-fuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00001), metrics=['acc'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=2)"
      ],
      "metadata": {
        "id": "wtKU7vP3-S8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}