{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOrLT4trTkRX"
      },
      "outputs": [],
      "source": [
        "text = open('/content/pianoabc.txt', 'r').read() #r for read\n",
        "print(text)\n",
        "\n",
        "unique_text = list(set(text)) #make unique bag of words\n",
        "unique_text.sort()\n",
        "print(unique_text)\n",
        "\n",
        "#utilities\n",
        "text_to_num = {}\n",
        "num_to_text = {}\n",
        "\n",
        "for i, data in enumerate(unique_text):\n",
        "  text_to_num[data] = i\n",
        "  num_to_text[i] = data\n",
        "\n",
        "print(text_to_num)\n",
        "print(num_to_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "numberized_text = []\n",
        "\n",
        "for i in text:\n",
        "  numberized_text.append( text_to_num[i] )\n",
        "\n",
        "print(numberized_text)\n",
        "\n",
        "X = [] #input = 25 letters\n",
        "Y = [] #key = 26th letter\n",
        "\n",
        "for i in range(0 , len(numberized_text) - 25):\n",
        "  X.append( numberized_text[i: i+25] )\n",
        "  Y.append( numberized_text[i+25] )\n",
        "\n",
        "print(X[0 : 5])\n",
        "print(Y[0 : 5])\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print( np.array(X).shape )\n",
        "print( np.array(Y).shape )\n",
        "\n",
        "X = tf.one_hot(X, 31) #number of unique letter = 31\n",
        "Y = tf.one_hot(Y, 31)\n",
        "print(X[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdk7-ZDEZlqr"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM( 100, input_shape=(25,31) ),\n",
        "    tf.keras.layers.Dense( 31, activation=\"softmax\") #predict next among 31 letters = category problem\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #sparse_categorical_crossentropy if not one hot encoded\n",
        "\n",
        "model.fit( X, Y, batch_size=64, epochs=30, verbose=2 ) #update weight value after training 64, verbose=2 to reduce print output during training\n",
        "\n",
        "model.save('drive/My Drive/model1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmfUIcwlcDc2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "Pmodel = tf.keras.models.load_model('drive/My Drive/Colab Notebooks/model1')\n",
        "\n",
        "text = open('/content/pianoabc.txt', 'r').read() #r for read\n",
        "\n",
        "unique_text = list(set(text)) #make unique bag of words\n",
        "unique_text.sort()\n",
        "\n",
        "#utilities\n",
        "text_to_num = {}\n",
        "num_to_text = {}\n",
        "\n",
        "for i, data in enumerate(unique_text):\n",
        "  text_to_num[data] = i\n",
        "  num_to_text[i] = data\n",
        "\n",
        "numberized_text = []\n",
        "\n",
        "for i in text:\n",
        "  numberized_text.append( text_to_num[i] )\n",
        "\n",
        "print(numberized_text)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "first_input = numberized_text[117: 117+25]\n",
        "first_input = tf.one_hot(first_input, 31)\n",
        "first_input = tf.expand_dims(first_input, axis=0) #change shape (25,31) to (1,25,31)\n",
        "print(first_input)\n",
        "\n",
        "predict_value = Pmodel.predict(first_input)\n",
        "predict_value = np.argmax(predict_value[0])\n",
        "print(predict_value)\n",
        "print(numberized_text[117+25])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7qI3oaZd9yp"
      },
      "outputs": [],
      "source": [
        "# 0. make first input\n",
        "\n",
        "# 1. predict next using Predict\n",
        "# 2. save predicted next letter in []\n",
        "\n",
        "# 3. remove the first of first predict\n",
        "# 4. put the predicted next letter at the back after one hot encoding\n",
        "\n",
        "# 5. predict with new input after expand dims\n",
        "\n",
        "music = []\n",
        "\n",
        "for i in range(200):\n",
        "\n",
        "  predict_value = Pmodel.predict(first_input)\n",
        "  predict_value = np.argmax(predict_value[0])\n",
        "  # print(predict_value)\n",
        "\n",
        "  music.append(predict_value)\n",
        "\n",
        "  next_input = first_input.numpy()[0][1:]\n",
        "  # print(next_input)\n",
        "\n",
        "  one_hot_num = tf.one_hot(predict_value, 31)\n",
        "  # print(one_hot_num)\n",
        "\n",
        "  first_input = np.vstack( [next_input, one_hot_num.numpy()] )\n",
        "  first_input = tf.expand_dims(first_input, axis=0)\n",
        "\n",
        "print(music)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn5pQqWBjlgQ",
        "outputId": "5e06fb3c-5cab-47f3-f61a-75e34cea670e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2BG\"C\"cc/2c/2\"G\"dd/2B/2\"D\"A/2F/2D/2F/2A/2D/2F/2A/2\"D\"f/2e/2d/2f/2\"A\"e/2c/2A/2c/2\"D\"B/2A/2F/2A/2\"G\"G/2A/2B/2c/2\"D7\"d/2c/2B/2A/2\"G\"GB/2c/2dB\"D\"A/2F/2G/2A/2B/2A/2G/2F/2\"D\"D/2E/2F/2G/2\"A7\"A/2B/2A/2G/2\"D\"F\n"
          ]
        }
      ],
      "source": [
        "music_text = []\n",
        "\n",
        "for i in music:\n",
        "  music_text.append(num_to_text[i])\n",
        "\n",
        "print(''.join(music_text))\n",
        "\n",
        "# ABC notation player\n",
        "# http://www.tradtunedb.org.uk/#/editor"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
